{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ICS 635 - Assignment 4\n",
    "> Derek Garcia\n",
    "\n",
    "## Load and Normalize FashionMNIST"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16910c78833e2b4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Download training data\n",
    "fashion_train_data = datasets.FashionMNIST(\n",
    "    root='./data',  # save images to ./data\n",
    "    train=True,     # training data\n",
    "    download=True,  # download locally\n",
    "    transform=transforms.ToTensor()     # Normalize the images to the range [0,1]\n",
    ")\n",
    "# split into 80/20 testing and validation\n",
    "size = len(fashion_train_data)\n",
    "train_size = int(0.8 * size)\n",
    "validation_size = size - train_size\n",
    "train, validation = random_split(fashion_train_data, [train_size, validation_size])\n",
    "\n",
    "# download the testing data\n",
    "test = datasets.FashionMNIST(\n",
    "    root='./data',  # save images to ./data\n",
    "    train=False,    # testing data\n",
    "    download=True,  # download locally\n",
    "    transform=transforms.ToTensor()     # Normalize the images to the range [0,1]\n",
    ")\n",
    "\n",
    "# create loaders\n",
    "train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build the Baseline CNN Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "743fa0050aac4943"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Tutorial: https://www.youtube.com/watch?v=pDdP0TFzsoQ\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device: \", device_str)\n",
    "device = torch.device(device_str)\n",
    "\n",
    "# CNN generic for later functions\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "# implement Convolutional neural net\n",
    "class BaselineCNN(CNN):\n",
    "    def __init__(self, kernel_size=3, out_channels=32):\n",
    "        \"\"\"\n",
    "        Create a baseline CNN model\n",
    "        \n",
    "        :param kernel_size: size of the sliding window the conv layer uses to scan the image (default: 3) - standard\n",
    "        :param out_channels: Number of kernel filters to use (default: 32) - not to overfit early on\n",
    "        \"\"\"\n",
    "        super(BaselineCNN, self).__init__()\n",
    "        # create one layer for baseline\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,              # dataset is grayscale, so only 1 channel\n",
    "            out_channels=out_channels,  # Number of kernel filters to use\n",
    "            kernel_size=kernel_size,    # n x n size of kernel filter\n",
    "            padding=kernel_size // 2    # preserve spatial dimensions\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 kernel and stride of 2\n",
    "        # fully connected layer\n",
    "        # n filters x image size / 2 (pooling) x image size / 2 (pooling), 10 possible classes for FashionMNIST\n",
    "        self.fc1 = nn.Linear(out_channels * 14 * 14, 10)  \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))    # apply pool to actuation function for first conv layer\n",
    "        x = x.view(-1, 32 * 14 * 14)    # must match input to fc1\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d83c6ba72cc0e315",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Train, Validate and Test Methods"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97284e6142356db2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from typing import Tuple, Literal\n",
    "\n",
    "\n",
    "def iter_dataset(model: CNN, mode: Literal['train', 'eval'], loader: DataLoader, \n",
    "                 criterion: CrossEntropyLoss, optimizer: SGD) -> Tuple[CNN, float, float]:\n",
    "    \"\"\"\n",
    "    Iterate over a dataset and compute loss\n",
    "    \n",
    "    todo - different criterion and optimizer classes?\n",
    "    :param model: Model to iter data over\n",
    "    :param mode: Model in train or eval mode\n",
    "    :param loader: loader of data\n",
    "    :param criterion: loss function\n",
    "    :param optimizer: optimizer\n",
    "    :return: the updated model, loss, accuracy\n",
    "    \"\"\"\n",
    "    # init running totals\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # set model mode and update gradiant\n",
    "    match mode:\n",
    "        case 'train':\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        case 'eval':\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)   # no_grad disables gradiant calc to save memory b/c not updating weights\n",
    "            \n",
    "    # iter through data\n",
    "    for images, labels in loader:\n",
    "        # designate cpu or gpu to process\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)   # calc loss\n",
    "        \n",
    "        # Backward pass if training\n",
    "        if mode == 'train':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # track loss\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # track accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        # sum correct matches\n",
    "        correct += torch.sum(predicted == labels).item()\n",
    "    # always reset to true\n",
    "    torch.set_grad_enabled(True)    \n",
    "    # calc return the updated model and stats\n",
    "    loss = running_loss / len(loader.dataset)\n",
    "    acc = (correct / total) * 100\n",
    "    return model, loss, acc\n",
    "\n",
    "\n",
    "def train(model: CNN, criterion: CrossEntropyLoss, optimizer: SGD, epochs: int = 5) -> CNN:\n",
    "    \"\"\"\n",
    "    Train a model and return the best results\n",
    "    \n",
    "    :model: CNN model to be trained\n",
    "    :param criterion: loss function\n",
    "    :param optimizer: optimizer\n",
    "    :param epochs: Number of training epochs (default: 5)\n",
    "    :return: Best model from training epochs\n",
    "    \"\"\"\n",
    "\n",
    "    # init variables to track the best epoch\n",
    "    best_val_loss = float('inf')    # set to infinity so first epoch is always best\n",
    "    best_val_epoch = 0\n",
    "    best_model_wts = None\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        # training loop\n",
    "        model, train_loss, train_acc = iter_dataset(model, 'train', train_loader, criterion, optimizer)\n",
    "    \n",
    "        # validation loop\n",
    "        model, val_loss, val_acc = iter_dataset(model, 'eval', validation_loader, criterion, optimizer)\n",
    "    \n",
    "        # print stats\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}% - \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save model if beats previous\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_epoch = epoch\n",
    "            best_model_wts = model.state_dict()     # save model as dict\n",
    "            \n",
    "    # after all epochs, use best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"Best model: epoch {best_val_epoch + 1}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test(model: CNN, criterion: CrossEntropyLoss, optimizer: SGD) -> None:\n",
    "    \"\"\"\n",
    "    Test the model and print results\n",
    "    \n",
    "    :param model: Model to test\n",
    "    :param criterion: loss function\n",
    "    :param optimizer: optimizer\n",
    "    \"\"\"\n",
    "    # Test model\n",
    "    model, test_loss, test_acc = iter_dataset(model, 'eval', test_loader, criterion, optimizer)\n",
    "    # print final results\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "486eb28060f00969",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and Test the Baseline Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2693714411c63552"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "baseline_model =  BaselineCNN().to(device)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()   # loss function\n",
    "optimizer = torch.optim.SGD(baseline_model.parameters()) # optimizer\n",
    "\n",
    "best_baseline_model = train(baseline_model, criterion, optimizer, epochs=2)\n",
    "test(best_baseline_model, criterion, optimizer)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "230ea272fbe69482",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modification 1: Adding a Second Layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75bb8f02ee343ffd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TwoLayerCNN(CNN):\n",
    "    def __init__(self, kernel_size=3, out_channels=32):\n",
    "        \"\"\"\n",
    "        Create a Two Layer CNN model\n",
    "        \n",
    "        :param kernel_size: size of the sliding window the conv layer uses to scan the image (default: 3) - standard\n",
    "        :param out_channels: Number of kernel filters to use (default: 32) - not to overfit early on\n",
    "        \"\"\"\n",
    "        super(TwoLayerCNN, self).__init__()\n",
    "        # create first layer\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,              # dataset is grayscale, so only 1 channel\n",
    "            out_channels=out_channels,  # Number of kernel filters to use\n",
    "            kernel_size=kernel_size,    # n x n size of kernel filter\n",
    "            padding=kernel_size // 2    # preserve spatial dimensions\n",
    "        )\n",
    "        \n",
    "        # create second layer\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,   # previous layer has 32 out channels\n",
    "            out_channels=out_channels,  # Number of kernel filters to use\n",
    "            kernel_size=kernel_size,    # n x n size of kernel filter\n",
    "            padding=kernel_size // 2    # preserve spatial dimensions\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 kernel and stride of 2\n",
    "        # fully connected layer\n",
    "        # n filters x image size / 2 (pooling) / 2 (2nn pooling) x image size / 2 (pooling) / 2 (2nn pooling), 10 possible classes for FashionMNIST\n",
    "        self.fc1 = nn.Linear(out_channels * 7 * 7, 10)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))    # apply pool to actuation function for first conv layer\n",
    "        x = self.pool(F.relu(self.conv2(x)))    # apply pool to actuation function for 2nd conv layer\n",
    "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "two_layer_model =  TwoLayerCNN().to(device)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()   # loss function\n",
    "optimizer = torch.optim.SGD(two_layer_model.parameters()) # optimizer\n",
    "\n",
    "best_two_layer_model = train(two_layer_model, criterion, optimizer, epochs=2)\n",
    "test(best_two_layer_model, criterion, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96834f81d088bc47",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
